import dragon

import argparse
import multiprocessing as mp
import time
import threading


def get_args():
    parser = argparse.ArgumentParser(description="All-all connection/queue test")

    parser.add_argument("--num_workers", type=int, default=4, help="number of workers in all-all")

    parser.add_argument("--iterations", type=int, default=100, help="number of iterations to do")

    parser.add_argument(
        "--burn_iterations", type=int, default=5, help="number of iterations to burn first time"
    )

    parser.add_argument(
        "--lg_message_size", type=int, default=4, help="log base 2 of msg size between each pair"
    )

    parser.add_argument("--dragon", action="store_true", help="run with dragon objs in dragon-style pattern")
    parser.add_argument("--dragon_compare", action="store_true", default=False, help="run with dragon objs and mp-native compatible patterns")
    parser.add_argument("--queues", action="store_true", help="measure aa with per-worker queues")
    my_args = parser.parse_args()

    assert my_args.lg_message_size <= 24, "arbitrary limit: 16MB message size"

    return my_args


def test_worker_conn(links, result_link, msg_size, total_iterations):
    """
    Worker function for both native multiprocessing and dragon
    Resources are generated by the initial process, which for dragon means poor multi-node scaling
    """
    # Output
    result_timings = []
    # Empty msg of size N bytes
    my_msg = bytearray(msg_size)

    def send_stuff():
        for link in links:
            link.send(my_msg)

    def recv_stuff():
        for link in links:
            _ = link.recv()

    for _ in range(total_iterations):
        start = time.perf_counter()

        send_th = threading.Thread(target=send_stuff)
        recv_th = threading.Thread(target=recv_stuff)

        send_th.start()
        recv_th.start()
        send_th.join()
        recv_th.join()

        result_timings.append(time.perf_counter() - start)

    result_link.send(result_timings)


# messages can mix between workers between iterations - there really
# ought to be a barrier - but the books balance at the end and this
# is meant to be more of a stress/comparison test anyway than
# a serious all-all.
def test_worker_queue(queues, my_idx, result_link, msg_size, total_iterations):
    """
    Worker function for both native multiprocessing and dragon
    Resources are generated by the initial process, which for dragon means poor multi-node scaling
    """
    result_timings = []
    my_msg = bytearray(msg_size)

    my_q = queues[my_idx]
    their_q = []
    for idx, q in enumerate(queues):
        if idx != my_idx:
            their_q.append(q)

    def send_stuff():
        for q in their_q:
            q.put(my_msg)

    def recv_stuff():
        for _ in range(len(their_q)):
            msg = my_q.get()
            assert msg_size == len(msg)

    for it_cnt in range(total_iterations):
        start = time.perf_counter()

        send_th = threading.Thread(target=send_stuff)
        recv_th = threading.Thread(target=recv_stuff)

        send_th.start()
        recv_th.start()
        send_th.join()
        recv_th.join()

        result_timings.append(time.perf_counter() - start)

    result_link.send(result_timings)



def test_worker_dragon_queue(queues, my_idx, result_link, msg_size, total_its):
    """
    Worker function for Dragon queues
    Native multiprocessing cannot share Queue objects between spawned processes, but Dragon can
    This offers better performance, as well as scalability to multi-node
    """
    # Create a per-process queue that Dragon can pass around
    # This provides significant on-node performance as well as multi-node performance
    my_q = mp.Queue(maxsize=len(queues)-1)
    my_msg = bytearray(msg_size)
    result_timings = []

    # Send process-made queue to all other workers
    for idx, q in enumerate(queues):
        if my_idx != idx:
            q.put(my_q)

    # Collect all the queues that have been sent to us
    their_q = []
    for i in range(len(queues)-1):
        q = queues[my_idx].get()
        their_q.append(q)

    del queues # Attempt to free up resource

    def send_stuff():
        for q in their_q:
            q.put(my_msg)

    def recv_stuff():
        for _ in range(len(their_q)):
            msg = my_q.get()
            assert msg_size == len(msg)

    for _ in range(total_its):
        start = time.perf_counter()

        send_th = threading.Thread(target=send_stuff)
        recv_th = threading.Thread(target=recv_stuff)

        send_th.start()
        recv_th.start()
        send_th.join()
        recv_th.join()

        result_timings.append(time.perf_counter() - start)

    result_link.send(result_timings)


def test_worker_dragon_conn(queues, my_idx, result_link, msg_size, total_iterations):
    """
    Worker function for both native multiprocessing and dragon, but written similar to dragon_queue
    This generates resources per process.
    Native and Dragon can both pass these resources between processes
    For Dragon this also enables multi-node scaling
    """
    my_msg = bytearray(msg_size)
    result_timings = []

    # Generate connection objects and pass them around
    # Queue is used here for this purpose, may be a less resource-hungry method to do so
    my_links = []
    for idx, q in enumerate(queues):
        if my_idx != idx:
            a, b = mp.Pipe()
            my_links.append(a)
            q.put(b)

    their_links = []
    for i in range(len(queues)-1):
        conn = queues[my_idx].get()
        their_links.append(conn)

    del queues # Attempt to free up resource

    def send_stuff():
        for conn in their_links:
            conn.send(my_msg)

    def recv_stuff():
        for conn in my_links:
            msg = conn.recv()
            assert msg_size == len(msg)


    for _ in range(total_iterations):
        start = time.perf_counter()

        send_th = threading.Thread(target=send_stuff)
        recv_th = threading.Thread(target=recv_stuff)

        send_th.start()
        recv_th.start()
        send_th.join()
        recv_th.join()

        result_timings.append(time.perf_counter() - start)

    result_link.send(result_timings)

def run_test(with_queues, nworkers, its, burns, msg_sz, is_dragon, comparison):
    # burns = warmup iterations
    total_iterations = burns + its

    # Return links for results of each process
    result_links = [mp.Pipe(duplex=False) for _ in range(nworkers)]

    queues = [mp.Queue(maxsize=nworkers) for _ in range(nworkers)]
    all_workers = []
    if with_queues:
        # Build list of queues for processes
        print(f"using {nworkers} Queues")

        # Build list of proccesses for all workers
        # Underlying implementation details mean Dragon can pass queue objects after spawn, but native cannot
        # Hence two slightly different functions
        if is_dragon and not comparison:
            all_workers = [
                mp.Process(
                    target=test_worker_dragon_queue,
                    args=(queues, i, result_links[i][1], msg_sz, total_iterations)
                )
                for i in range(nworkers)
            ]
        else:
            all_workers = [
                mp.Process(
                    target=test_worker_queue,
                    args=(queues, i, result_links[i][1], msg_sz, total_iterations)
                )
                for i in range(nworkers)
            ]
    else:
        # Dragon generates connection objections in spawned processes
        if is_dragon and not comparison:
            all_workers = [
                mp.Process(
                    target=test_worker_dragon_conn,
                    args=(queues, i, result_links[i][1], msg_sz, total_iterations)
                )
                for i in range(nworkers)
            ]

        else:
            # Generate all pipes in main process
            print(f"using {nworkers * (nworkers - 1) // 2} Pipes")
            all_links = {}

            # full duplex links; nworkers * (nworkers-1)/2 of them
            for i in range(nworkers):
                for j in range(i, nworkers):
                    all_links[i, j] = mp.Pipe()

            for i in range(nworkers):
                # first end if other's index less than yours,
                # second end if other's index greater than yours
                links = []
                for k in range(nworkers):
                    if k != i:
                        links.append(all_links[min(i, k), max(i, k)][int(k < i)])

                # Build a list of processes with an approrpriate start-end link and output link for results
                proc = mp.Process(
                    target=test_worker_conn, args=(links, result_links[i][1], msg_sz, total_iterations)
                )

                all_workers.append(proc)

    # Start all workers
    for worker in all_workers:
        worker.start()

    # Collect averages and totals
    avg_times = []
    total_times = []
    for i in range(nworkers):
        # Exclude "spin up" burn times from data
        result = result_links[i][0].recv()[burns:]
        total_times.append(sum(result))
        avg_times.append(total_times[i] / its)

    # Math
    avg_aa_completion_time = sum(avg_times) / nworkers  # seconds
    bandwidth = msg_sz * nworkers / avg_aa_completion_time  # bytes/second

    msg_size_in_k = msg_sz / (2**10)
    bw_in_mb_sec = bandwidth / (2**20)
    completion_time_in_ms = avg_aa_completion_time * 1000

    # Close all processes
    for worker in all_workers:
        worker.join()

    print(f"{nworkers=} {its=} {msg_size_in_k=} {completion_time_in_ms=:.3f} {bw_in_mb_sec=:.2f}")


def main():
    args = get_args()

    if args.dragon or args.dragon_compare:
        print("using dragon runtime")
        mp.set_start_method("dragon")
    else:
        # NOTE: Do not call with dragon launcher and using queues
        #       Results in an odd bug in v0.4
        print("using regular mp libs/calls")
        mp.set_start_method("spawn")

    run_test(
        with_queues=args.queues,
        nworkers=args.num_workers,
        msg_sz=2**args.lg_message_size,
        its=args.iterations,
        burns=args.burn_iterations,
        is_dragon=args.dragon,
        comparison=args.dragon_compare
    )


if __name__ == "__main__":
    exit(main())
