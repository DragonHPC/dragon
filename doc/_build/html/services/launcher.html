<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Launcher &mdash; Dragon  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Global Services" href="global_services.html" />
    <link rel="prev" title="Services" href="services.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Dragon
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../start/start.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uguide/uguide.html">Users Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pguide/pguide.html">Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cbook/cbook.html">Solution Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks/benchmarks.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ref/ref.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infrastructure/infrastructure.html">Infrastructure</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="services.html">Services</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Launcher</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#launcher-single-node-architecture">Launcher Single Node Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="#launcher-multi-node-architecture">Launcher Multi Node Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="#launcher-components">Launcher Components</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#the-launcher-s-network-components">The Launcher’s Network Components</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mrnet">MRNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="#starting-the-launcher">Starting the Launcher</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#launcher-messages">Launcher Messages</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Starting the Launcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="#launcher-server-mode">Launcher Server Mode</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#state-transitions">State Transitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#supporting-jupyter-notebooks">Supporting Jupyter Notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="global_services.html">Global Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="local_services.html">Local Services</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../components/components.html">Low-level Components</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Dragon</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="services.html">Services</a></li>
      <li class="breadcrumb-item active">Launcher</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/services/launcher.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="launcher">
<span id="id1"></span><h1>Launcher<a class="headerlink" href="#launcher" title="Permalink to this heading"></a></h1>
<p><strong>DISCLAIMER: Much of this is out of date following removal of CTI and MRNet. Refer to</strong> <a class="reference internal" href="../infrastructure/multi_node_deployment.html#multinodedeployment"><span class="std std-ref">Multi Node Deployment</span></a>
<strong>for most accurate info</strong></p>
<p>The Launcher is responsible for communicating from the user to <a class="reference internal" href="global_services.html#globalservices"><span class="std std-ref">Global Services</span></a> and <a class="reference internal" href="local_services.html#localservices"><span class="std std-ref">Local Services</span></a>.
The Launcher supports <a class="reference internal" href="../infrastructure/single_node_deployment.html#singlenodedeployment"><span class="std std-ref">Single Node Deployment</span></a> as well as <a class="reference internal" href="../infrastructure/multi_node_deployment.html#multinodedeployment"><span class="std std-ref">Multi Node Deployment</span></a>.</p>
<p><a class="reference internal" href="../infrastructure/single_node_deployment.html#singlenodedeployment"><span class="std std-ref">Single Node Deployment</span></a> and <a class="reference internal" href="../infrastructure/multi_node_deployment.html#multinodedeployment"><span class="std std-ref">Multi Node Deployment</span></a>, have different requirements for launching
applications. In both cases there is a Launcher frontend  and a Launcher backend`. In the multi-node case
additional components come into play to set up the communication between the frontend and backend. The
Launcher can be run in <a class="reference internal" href="#launcherservermode"><span class="std std-ref">Launcher Server Mode</span></a> to support user-defined interaction between the login node
and compute nodes.</p>
<p><strong>FIXME: Some more detail on the requirements for multi-node and single-node would be good here</strong></p>
<section id="launcher-single-node-architecture">
<span id="launchersinglenodearchitecture"></span><h2>Launcher Single Node Architecture<a class="headerlink" href="#launcher-single-node-architecture" title="Permalink to this heading"></a></h2>
<figure class="align-default" id="id4">
<img alt="../_images/launcher_single_node.svg" src="../_images/launcher_single_node.svg" /><figcaption>
<p><span class="caption-number">Fig. 29 </span><span class="caption-text"><strong>Image 1: Single node architecture of the Launcher component</strong></span><a class="headerlink" href="#id4" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<figure class="align-default" id="id5">
<img alt="services/images/singlenodelauncher.png" src="services/images/singlenodelauncher.png" />
<figcaption>
<p><span class="caption-number">Fig. 30 </span><span class="caption-text"><strong>Figure 2: Single-node Launcher/Backend Components</strong></span><a class="headerlink" href="#id5" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>In a single node deployment of Dragon, the launcher consists of the following components:</p>
<ul class="simple">
<li><p><em>Launcher Frontend</em>: User input and output.</p></li>
<li><dl class="simple">
<dt><em>Launcher Backend</em>:</dt><dd><ul>
<li><p>Startup of and communication with <a class="reference internal" href="local_services.html#localservices"><span class="std std-ref">Local Services</span></a> using standard POSIX pipes.</p></li>
<li><p>Communication with all Dragon <a class="reference internal" href="services.html#services"><span class="std std-ref">Services</span></a> via <a class="reference internal" href="../infrastructure/messages_api.html#messages"><span class="std std-ref">Infrastructure Messages</span></a> through <span class="xref std std-ref">Channels</span>.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>In the single-node case, the Launcher frontend starts the Launcher Backend which then in turn starts the
<a class="reference internal" href="local_services.html#localservices"><span class="std std-ref">Local Services</span></a>. The Launcher Front End communicates with the Launcher Back End via its stdin and stdout
streams. The Launcher Back End communicates with the Shepherd via its stdin and stout during startup and
teardown. After startup and before teardown all communication between the Launcher Back End, the Shepherd, and
<a class="reference internal" href="global_services.html#globalservices"><span class="std std-ref">Global Services</span></a> occurs over <span class="xref std std-ref">Channels</span>. See <a class="reference internal" href="../infrastructure/single_node_deployment.html#singlenodebringup"><span class="std std-ref">Single Node Bringup</span></a> and <a class="reference internal" href="../infrastructure/single_node_deployment.html#singlenodeteardown"><span class="std std-ref">Single Node Teardown</span></a>
for details on the process.</p>
</section>
<section id="launcher-multi-node-architecture">
<span id="launchermultinodearchitecture"></span><h2>Launcher Multi Node Architecture<a class="headerlink" href="#launcher-multi-node-architecture" title="Permalink to this heading"></a></h2>
<figure class="align-default" id="id6">
<img alt="../_images/launcher_multi_node.svg" src="../_images/launcher_multi_node.svg" /><figcaption>
<p><span class="caption-number">Fig. 31 </span><span class="caption-text"><strong>Image 3: Multi node architecture of the Launcher component</strong></span><a class="headerlink" href="#id6" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<figure class="align-default" id="id7">
<img alt="services/images/launchercomponents.png" src="services/images/launchercomponents.png" />
<figcaption>
<p><span class="caption-number">Fig. 32 </span><span class="caption-text"><strong>Figure 4: Multi-node Launcher/Backend Components</strong></span><a class="headerlink" href="#id7" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>In the multi-node case, shown in figures 3 and 4, the Launcher Front End uses the workload manager to start
the  Shepherd on every node through <span class="xref std std-ref">CTI</span>. It then starts the Network Front End which creates an MRNet
Server Front End which creates a scalable communication tree that eventually connects to a Network Back End.
The Launcher Back End  component is started by MRNet and communication between the Launcher Back End and the
Shepherd is accomplished via a pair of Posix message queues during startup and teardown. After startup and
before teardown all communication between the Backend, the Shepherd, and Global Services occurs over channels.</p>
<p>The Launcher Back End starts the Network Back End during startup. The Network Back End the creates a
MRNetServer Back end which attaches to the MRNet network. Both the Launcher Front End and the Launcher Back
End communicate with their corresponding Network Front End and Back End components via stdin and stdout of
their respective processes.</p>
<p>Internally, the <em>Launcher Front End</em> is composed of a server that routes messages to and from the user. The
user interacts with the <em>Command Processor</em> which is a <em>Read Evaluate Print Loop</em> for Python. The command
processor is a full-fledged Python interpreter with several predefined functions for invoking the various
<em>Launcher</em> commands. The command definitions are given in the <span class="xref std std-ref">LauncherCommands</span> section.</p>
<p>Not depicted in figure 4, the <a class="reference internal" href="global_services.html#globalservices"><span class="std std-ref">Global Services</span></a> and its <span class="xref std std-ref">Channels</span> are only present on the primary
node. All other components on the compute node are present on every compute node.</p>
</section>
<section id="launcher-components">
<span id="launchercomponents"></span><h2>Launcher Components<a class="headerlink" href="#launcher-components" title="Permalink to this heading"></a></h2>
<p>During initialization the <em>Launcher Front End</em> creates the <em>Network Front End</em> as a process. The <em>Network
Front End</em> creates an instance of the MRNetServerFE object and provides it a <em>callback</em> that is invoked when
data comes from the <em>MRNet Server</em> to the  <em>Network Front End</em>. The callback handler writes the message to
stdout, which the <em>Launcher Front End</em> can then read. The <em>Launch Front End</em> writes to stdin of the <em>Network
Front End</em> to send data across the MRNet Network to compute nodes. If the <em>Network Front End</em> receives an
<a class="reference internal" href="../infrastructure/messages_api.html#labroadcast"><span class="std std-ref">LABroadcast</span></a> message, it calls the broadcast method of the <em>MRNet Server Front End</em>.</p>
<p>The <em>Launcher Backend</em> is an AsyncIO process and monitors its stdout of the <em>Network Back End</em> (via an AsyncIO
task) and reads from the <em>Network Back End</em> pipe and to receive data coming from the front end. The <em>Network
Back End</em> provides a <em>callback handler</em> the the MRNetServerBE object to be called when data flows from the
front end. This <em>callback handler</em> writes any data to the stdout of the <em>Network Backend</em> which then gets read
by the <em>Launcher Back End’s</em> AsyncIO monitor task.</p>
<p>As mentioned, the <em>Network Front End</em> is a process and is started by the <em>Launcher Front End</em>. The <em>Network
Backend</em> is also a process and is started by <em>MRNet</em> as part of the bringup of an HPC job allocation under the
control of <em>slurm</em>. The Shepherd is brought up by CTI during startup.</p>
<p>In the case of single-node Dragon run-time services, the <em>Launcher Front End</em> is started by the user and the
<em>Launcher Front End</em> starts the <em>Launcher Back End</em> which in turn starts the Shepherd. All startup/teardown
communication between the components occurs on these stdin and stdout streams resulting from these process
creations.</p>
<p>In both multi-node and single-node mode, the <em>Launcher Back End</em> does not run as a managed process to be
consistent between the multi-node and single-node cases.</p>
<p>Any <a class="reference internal" href="../infrastructure/messages_api.html#labroadcast"><span class="std std-ref">LABroadcast</span></a> message ends up in the <em>Launcher Back End</em> which then unwraps the
broadcasted message and forwards it to the appropriate component, which as of this writing is always the
<em>Shepherd</em>. Currently there are two broadcasted messages, the <a class="reference internal" href="../infrastructure/messages_api.html#shhaltta"><span class="std std-ref">SHHaltTA</span></a> message and the
<a class="reference internal" href="../infrastructure/messages_api.html#shteardown"><span class="std std-ref">SHTearDown</span></a> message.</p>
<p><strong>FIXME: We could introduce separate frontend and backend descriptions here. They are references at a lot of places.</strong></p>
<section id="the-launcher-s-network-components">
<h3>The Launcher’s Network Components<a class="headerlink" href="#the-launcher-s-network-components" title="Permalink to this heading"></a></h3>
<p>The Network front and back end program components of the launcher are responible for communicating with their
respctive Launcher front end and back end components. The code for both the network front end and back end
components of the are relatively simple applications employing the two classes MRNetServerFE and
MRNetServerBE. The network front end and back end programs create an instance of their respective class and
then read from standard input and send any standard input on to the other side. Both components write any
received messages from the other side (via their callback handler) to standard output. The two programs are
provided below for reference.</p>
<p>NOTE: The Launcher’s Network Front End has an external dependency on the <em>_tc</em> field of the <a class="reference internal" href="../infrastructure/messages_api.html#labroadcast"><span class="std std-ref">LABroadcast</span></a> message being set to 68.</p>
<section id="network-front-end">
<span id="launchernetworkfrontend"></span><h4>Network Front End<a class="headerlink" href="#network-front-end" title="Permalink to this heading"></a></h4>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;dragon/mrnetserverfe.hpp&gt;</span><span class="cp"></span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdlib&gt;</span><span class="cp"></span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;unistd.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;fstream&gt;</span><span class="cp"></span>

<span class="kt">void</span><span class="w"> </span><span class="nf">mrnet_callback</span><span class="p">(</span><span class="n">MRNetServerFE</span><span class="o">*</span><span class="w"> </span><span class="n">server</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">msg</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">msg</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">flush</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">bool</span><span class="w"> </span><span class="nf">file_exists</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">fileName</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">ifstream</span><span class="w"> </span><span class="n">infile</span><span class="p">(</span><span class="n">fileName</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">infile</span><span class="p">.</span><span class="n">good</span><span class="p">();</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="c1">// The argv arguments are passed to the MRNet backend program as</span>
<span class="c1">// command-line arguments.</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">try</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*&gt;</span><span class="w"> </span><span class="n">cti_args</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">cti_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">getenv</span><span class="p">(</span><span class="s">&quot;DRAGON_CTI_EXEC&quot;</span><span class="p">);</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cti_ptr</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nb">NULL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;DRAGON_CTI_EXEC value not found in environment.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>

<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">cti_exec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cti_ptr</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="n">cti_args</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">cti_exec</span><span class="p">.</span><span class="n">c_str</span><span class="p">());</span><span class="w"></span>

<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*&gt;</span><span class="w"> </span><span class="n">mrnetbe_args</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">mrnet_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">getenv</span><span class="p">(</span><span class="s">&quot;DRAGON_MRNETBE_EXEC&quot;</span><span class="p">);</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">mrnet_ptr</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nb">NULL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;DRAGON_MRNETBE_EXEC value not found in environment.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>

<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">mrnetbe_exec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mrnet_ptr</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="n">mrnetbe_args</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">mrnetbe_exec</span><span class="p">.</span><span class="n">c_str</span><span class="p">());</span><span class="w"></span>

<span class="w">        </span><span class="c1">// argv[0] is this executable which is not needed by the backend.</span>
<span class="w">        </span><span class="c1">// argv[1] is the dragon_mode set to &#39;hsta&#39;.</span>
<span class="w">        </span><span class="c1">// argv[2] is the extra manifest file required for the backend executable. This is the</span>
<span class="w">        </span><span class="c1">// path to the launchernetbe executable which is started via a Popen by the</span>
<span class="w">        </span><span class="c1">// DRAGON_MRNETBE_EXEC program.</span>
<span class="w">        </span><span class="c1">// Starting at argv[2] are any arguments needed by the backend executable</span>
<span class="w">        </span><span class="c1">// specified by the DRAGON_MRNETBE_EXEC environment variable.</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*&gt;</span><span class="w"> </span><span class="n">additionalManifestFiles</span><span class="p">;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">k</span><span class="o">&lt;</span><span class="n">argc</span><span class="p">;</span><span class="n">k</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="n">mrnetbe_args</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="n">k</span><span class="p">]);</span><span class="w"></span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">file_exists</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">                </span><span class="n">additionalManifestFiles</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="n">k</span><span class="p">]);</span><span class="w"></span>
<span class="w">            </span><span class="p">}</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>

<span class="w">        </span><span class="n">MRNetServerFE</span><span class="w"> </span><span class="n">server</span><span class="p">(</span><span class="n">cti_args</span><span class="p">,</span><span class="w"> </span><span class="n">mrnetbe_args</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">mrnet_callback</span><span class="p">,</span><span class="w"> </span><span class="n">environ</span><span class="p">,</span><span class="w"> </span><span class="n">additionalManifestFiles</span><span class="p">);</span><span class="w"></span>

<span class="w">        </span><span class="c1">// The first thing written to stdout is the number of nodes in the allocation.</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">server</span><span class="p">.</span><span class="n">get_num_nodes</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">flush</span><span class="p">;</span><span class="w"></span>

<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">msg</span><span class="p">;</span><span class="w"></span>

<span class="w">        </span><span class="c1">// A Broadcast message will contain &quot;_tc&quot;: 68 in it since this is the typecode</span>
<span class="w">        </span><span class="c1">// for a LABroadcast message.</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">bcast</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\&quot;</span><span class="s">_tc</span><span class="se">\&quot;</span><span class="s">: 68&quot;</span><span class="p">;</span><span class="w"></span>

<span class="w">        </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">getline</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">cin</span><span class="p">,</span><span class="w"> </span><span class="n">msg</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">msg</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">bcast</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">::</span><span class="n">npos</span><span class="p">)</span><span class="w"></span>
<span class="w">                </span><span class="n">server</span><span class="p">.</span><span class="n">send_all</span><span class="p">(</span><span class="n">msg</span><span class="p">);</span><span class="w"></span>
<span class="w">            </span><span class="k">else</span><span class="w"></span>
<span class="w">                </span><span class="n">server</span><span class="p">.</span><span class="n">send_primary</span><span class="p">(</span><span class="n">msg</span><span class="p">);</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>

<span class="w">        </span><span class="n">server</span><span class="p">.</span><span class="n">shutdown</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">catch</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">exception</span><span class="w"> </span><span class="o">&amp;</span><span class="n">exc</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="c1">// catch anything thrown within try block that derives from std::exception</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">exc</span><span class="p">.</span><span class="n">what</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="network-back-end">
<span id="launchernetworkbackend"></span><h4>Network Back End<a class="headerlink" href="#network-back-end" title="Permalink to this heading"></a></h4>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;unistd.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;dragon/mrnetserverbe.hpp&gt;</span><span class="cp"></span>

<span class="kt">void</span><span class="w"> </span><span class="nf">mrnet_callback</span><span class="p">(</span><span class="n">MRNetServerBE</span><span class="o">*</span><span class="w"> </span><span class="n">server</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">msg</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="c1">// Anything coming down the MRNet tree is written</span>
<span class="w">    </span><span class="c1">// to standard output for the piped parent process to read.</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">msg</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">flush</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">MRNetServerBE</span><span class="w"> </span><span class="n">server</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">mrnet_callback</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="c1">// After attaching to the MRNet the first thing is to</span>
<span class="w">    </span><span class="c1">// provide the node index to the backend launcher.</span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">server</span><span class="p">.</span><span class="n">get_node_id</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">flush</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">msg</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Anything coming from the parent process through</span>
<span class="w">    </span><span class="c1">// stdin is sent up to through the MRNet tree.</span>
<span class="w">    </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">getline</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">cin</span><span class="p">,</span><span class="w"> </span><span class="n">msg</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="n">server</span><span class="p">.</span><span class="n">send</span><span class="p">(</span><span class="n">msg</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="n">server</span><span class="p">.</span><span class="n">shutdown</span><span class="p">();</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
</section>
<section id="mrnet">
<h3>MRNet<a class="headerlink" href="#mrnet" title="Permalink to this heading"></a></h3>
<p>The MRNet is an open source API for constructing a tree communication structure between nodes in a distributed
system. The MRNet API comes out of the University of Wisconsin, Madison. The MRNet is used to start the
shepherd on each  node which in turn brings up other parts of the service.</p>
<p>See the <span class="xref std std-ref">MRNet</span> page for further details.</p>
</section>
<section id="starting-the-launcher">
<h3>Starting the Launcher<a class="headerlink" href="#starting-the-launcher" title="Permalink to this heading"></a></h3>
<p>In the multi-node version of Dragon, the Launcher is started by a wrapper program that
manages the allocation of a number of nodes via an salloc command. The SLURM workload manager
provides this salloc command for starting the Launcher. When a different workload manager
is used, then a different wrapper may be necessary. This wrapper accepts any parameters as specified
in the section on <a class="reference external" href="invoking-the-launcher">Invoking the Launcher</a>.</p>
<p>The Launcher wrapper requires one extra parameter, the argument -cores specifies how many
cores that Dragon is to be allocated on. The launcher then determines from the current partition
the minimum number of nodes that will be required to satisfy that request.
Then this value is passed on to the <em>salloc</em> command to acquire and allocation that satisfies the
user’s request and runs one instance
of the Shepherd per node so each is included in the set of Dragon run-time service nodes.</p>
<p>This Launcher wrapper sets required environment variables including the number of nodes for the allocation
and the <em>DRAGON_MODE</em> environment variable that indicates that dragon is running in <em>muitinode</em> mode.
The wrapper then executes the salloc command with the actual start of the launcher within it and any
launcher specific arguments passed into it.</p>
</section>
</section>
<section id="launcher-messages">
<h2>Launcher Messages<a class="headerlink" href="#launcher-messages" title="Permalink to this heading"></a></h2>
<p>Launcher specific message definitions can be found within the <a class="reference internal" href="../infrastructure/messages_api.html#launcherapi"><span class="std std-ref">Launcher Messages API</span></a>. Definitions for other
messages can be found within the <a class="reference internal" href="../infrastructure/messages_api.html#messages"><span class="std std-ref">Infrastructure Messages</span></a> section. Links to specific messages are provided within this
documentation as they appear.</p>
</section>
<section id="id2">
<h2>Starting the Launcher<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h2>
<p>In the multi-node version of Dragon, the Launcher is started by a wrapper program that
manages the allocation of a number of nodes via an salloc command. The SLURM workload manager
provides this salloc command for starting the Launcher. When a different workload manager
is used, then a different wrapper may be necessary. This wrapper accepts any parameters as specified
in the section on <a class="reference external" href="invoking-the-launcher">Invoking the Launcher</a>.</p>
<p>The Launcher wrapper requires one extra parameter, the argument -cores specifies how many
cores that Dragon is to be allocated on. The launcher then determines from the current partition
the minimum number of nodes that will be required to satisfy that request.
Then this value is passed on to the <em>salloc</em> command to acquire and allocation that satisfies the
user’s request and runs one instance
of the Shepherd per node so each is included in the set of Dragon run-time service nodes.</p>
<p>This Launcher wrapper sets required environment variables including the number of nodes for the allocation
and the <em>DRAGON_MODE</em> environment variable that indicates that dragon is running in <em>multinode</em> mode.
The wrapper then executes the salloc command with the actual start of the launcher within it and any
launcher specific arguments passed into it.</p>
</section>
<section id="launcher-server-mode">
<span id="launcherservermode"></span><h2>Launcher Server Mode<a class="headerlink" href="#launcher-server-mode" title="Permalink to this heading"></a></h2>
<p>This section provides details of running the <em>Dragon Launcher</em> in <em>Server Mode</em>.
This mode can be used to support any user-defined interaction between the login
node and compute nodes running under the <em>Dragon</em> run-time services. Server mode
may be necessary for some multi-node applications but can be used in single-node
as well allowing a server application to run in either environment.</p>
<figure class="align-default" id="id8">
<img alt="services/images/servermode.png" src="services/images/servermode.png" />
<figcaption>
<p><span class="caption-number">Fig. 33 </span><span class="caption-text"><strong>Figure 5: Dragon Server Mode</strong></span><a class="headerlink" href="#id8" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>In server mode there are two programs that are started by the launcher. The
<em>Server Front End</em> and the <em>Server Back End</em>. The front end runs on the login
node. The back end runs on the primary compute node. When the server front end
is started, it is started so that standard input and output are pipes.
On the back end the program is started and has access to the complete
Dragon run-time services.</p>
<figure class="align-default" id="id9">
<a class="reference internal image-reference" href="../_images/server.srms1.png"><img alt="../_images/server.srms1.png" src="../_images/server.srms1.png" style="width: 740.25px; height: 886.5px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 34 </span><span class="caption-text"><strong>Figure 6: PassThru Message Exchange</strong></span><a class="headerlink" href="#id9" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>The <em>Launcher</em> starts the
front end specifying that standard input and output are to be piped from/to
the launcher.</p>
<p>The <em>Server Back End</em> initiates contact with the <em>Server Front End</em> by sending a
<a class="reference internal" href="../infrastructure/messages_api.html#lapassthrubf"><span class="std std-ref">LAPassThruBF</span></a> message. Initiating the conversation by first
sending this message guarantees that the backend will be ready to accept
messages on its channel. The <em>Server Back End</em> creates a <em>channel</em> for receiving
messages from the  <em>Server Front End</em> and provides the <em>channel id</em> in this
initial <a class="reference internal" href="../infrastructure/messages_api.html#lapassthrubf"><span class="std std-ref">LAPassThruBF</span></a> message as the <em>r_c_uid</em> field. After
receiving this initial message, <em>Server Front End</em> can then send
<a class="reference internal" href="../infrastructure/messages_api.html#lapassthrufb"><span class="std std-ref">LAPassThruFB</span></a>  messages to the <em>Server Back End</em> using this
<em>channel id</em>.</p>
<p>From the perspective of the implementer of both the <em>Server Front End</em> and the
<em>Server Back End</em> the exact mechanics of sending and receiving these <em>passthru</em>
messages can be managed by a few of API calls.  From the <em>front end</em> the
<em>send_to_backend</em> function sends a <a class="reference internal" href="../infrastructure/messages_api.html#lapassthrufb"><span class="std std-ref">LAPassThruFB</span></a> message
containing  a user-defined string to a specified <em>channel id</em>. The
<em>send_to_backend</em> API call packages up the user-defined string into a
<a class="reference internal" href="../infrastructure/messages_api.html#lapassthrufb"><span class="std std-ref">LAPassThruFB</span></a> message and writes it to the output pipe of the
<em>Server Front End</em>. This is a convenience function only. A programmer can write
their own code to carry out this functionality.</p>
<p>From the <em>back end</em> the programmer may use a <em>send_to_frontend</em>  call to build
and send a <a class="reference internal" href="../infrastructure/messages_api.html#lapassthrubf"><span class="std std-ref">LAPassThruBF</span></a> message to the <em>front end</em>. The
<em>send_to_frontend</em> API call includes the <em>return channel id</em> as an argument. The
<em>send_to_frontend</em> packages up the data into a <a class="reference internal" href="../infrastructure/messages_api.html#lapassthrubf"><span class="std std-ref">:APassThruBF</span></a>
message and sends it to the <em>Dragon Back End</em> which then routes it to the
<em>Launcher</em> (through <em>MRNet</em> in the multi-node case) and through the <em>Launcher</em>
to the <em>Server Front End</em>. This is a convenience function only. A programmer can
write their own code to carry out this functionality.</p>
<p>The only messages passed from/to the <em>Front End Server</em> and to/from the <em>Back
End Server</em> are the two <em>PassThru</em> messages and optionally a <em>LASeverModeExit</em>
message to indicate that the backend server has exited.</p>
<p>Any output from the
back end that is to be shared with the front end must be wrapped up in
a <a class="reference internal" href="../infrastructure/messages_api.html#lapassthrubf"><span class="std std-ref">LAPassThruBF</span></a> message.</p>
<p>It is likely that the designer of
the front and back end services will design their own message structure to be
passed within the two <em>PassThru</em> messages. Any standard output or standard error
output generated by the <em>Back End Server</em> will automatically be written to the
console where the Launcher was invoked. If stdout or stderr is supposed to go to the
<em>Front End Server</em> then it must be captured by the <em>Back End Server</em> and routed
to the <em>Front End Server</em> in a <a class="reference internal" href="../infrastructure/messages_api.html#lapassthrubf"><span class="std std-ref">LAPassThruBF</span></a> message.</p>
<p>Likewise, two <em>receive</em> API calls are also available. The <em>receive_from_backend</em>
and  <em>receive_from_frontend</em> functions can be called to receive messages. The
two <em>receive</em> API calls are implemented as awaitables in Python to support the
AsyncIO framework.</p>
<p>The backend of the server can initiate shutdown of <em>Server Mode</em> by sending the
<em>LAServerModeExit</em> message to the launcher. When the launcher receives this message
it forwards it to the frontend of the server and also responds to the command processor,
allowing the <em>serve</em> command to complete.</p>
<p>[TBD: How is API exposed/imported by the programmer. Exact packaging/use of API
should be described here. If we were to decide to not expose infrastructure
messages, then appropriate bindings of these API calls would need to be provided
for C/C++ and Python (and others?). In Python the interface should support the
AsyncIO framework.]</p>
<p>There are many possible uses for <em>Server Mode</em>. The next section provides
details of using <em>Server Mode</em> for implementing a <em>Jupyter Notebook Kernel</em>.
Another possible use is in providing a Python debugger interface to the <em>Dragon
Run-time Services</em>. Finally, it would be possible to use this mode to provide
HPC management services on a system. In each of these cases the dynamic nature
of Python would allow the applications to be developed incrementally and tested
incrementally, potentially saving a lot of costly development and testing time.</p>
<section id="state-transitions">
<h3>State Transitions<a class="headerlink" href="#state-transitions" title="Permalink to this heading"></a></h3>
<figure class="align-default" id="id10">
<img alt="services/images/launcherstates.png" src="services/images/launcherstates.png" />
<figcaption>
<p><span class="caption-number">Fig. 35 </span><span class="caption-text"><strong>Figure 7: State Diagram</strong></span><a class="headerlink" href="#id10" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>The four states of the Launcher define four states the launcher could be in. In
addition, there are a few more states during initialization that are not described
here. The transitions
shown in  the state diagram document how the Launcher moves from one state to
another. The state diagram  does not show all commands possible in command mode.
Specifically, commands that don’t cause a transition to a state are not shown in
the state diagram.</p>
<p>The <em>Initialization</em> State takes care of bringing up the Dragon run-time services and then
transitioning to the <em>Command</em> state. The <em>Exit</em> state takes care of bringing down the
Dragon run-time services and terminating the launcher.</p>
<p>During initialization, if a program file, <em>PROG</em>, was provided on the
command-line (not for server mode), then the following commands are issued in
<em>Command Mode</em> once initialization is complete.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">it</span> <span class="o">=</span> <span class="n">launch</span><span class="p">(</span><span class="n">exe</span><span class="o">=</span><span class="s2">&quot;PROG&quot;</span><span class="p">)</span>
<span class="n">join</span><span class="p">(</span><span class="n">it</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>If <em>PROG</em> is not executable then the <em>exe</em> is <em>python3</em> and <em>PROG</em> is passed as an
argument to the launch command.
During initialization, if <em>Server Mode</em> is specified, then the following commands are issued to
the <em>Command Mode</em> once intialization is complete.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">serve</span><span class="p">(</span><span class="n">frontendprog</span><span class="p">,</span> <span class="n">backendprog</span><span class="p">,</span> <span class="n">frontendargs</span><span class="p">,</span> <span class="n">backendargs</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>And, if <em>-r</em> is specified, then the following command is issued to the command processor where
<em>PROG</em> is the program given on the command-line.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;PROG&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In this case, the <em>PROG</em> is a launch program and is run on the login node to control launching
of programs within the Dragon environment.</p>
<p>If <em>-i</em> is NOT specified on the command-line and the program exits, then the following
command is fed to the command processor when the program exits (i.e. after the join completes).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">exit</span><span class="p">()</span>
</pre></div>
</div>
<p>As a general rule, while initially in <em>Command</em> mode, commands will be
issued automatically for the simple cases of running a single program or
starting server mode. Command mode becomes visible to the user when the user
uses the <em>-i</em> option from the command line.</p>
</section>
<section id="supporting-jupyter-notebooks">
<h3>Supporting Jupyter Notebooks<a class="headerlink" href="#supporting-jupyter-notebooks" title="Permalink to this heading"></a></h3>
<p><em>Server Mode</em> was designed to support any distributed implementation of a server
between a login node and the primary compute node. One use case of this
functionality is in the implementation of a Jupyter Notebook kernel that runs
within the Dragon run-time services.</p>
<figure class="align-default" id="id11">
<img alt="services/images/jupytermode.png" src="services/images/jupytermode.png" />
<figcaption>
<p><span class="caption-number">Fig. 36 </span><span class="caption-text"><strong>Figure 8: Dragon Server Mode for Jupyter Notebooks</strong></span><a class="headerlink" href="#id11" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>There are two supported methods to run a Jupyter notebook in conjunction with
the Dragon run-time services. The two methods have differing characteristics.</p>
<ul class="simple">
<li><p>Fat Login Mode</p></li>
<li><p>Server Mode</p></li>
</ul>
<p>Running the Jupyter notebook on a fat login node means that the notebook can be
long running. In this case, the IPython Kernel runs on the fat login node. From
within that IPython kernel a user can start a Dragon job by using the REPL
command mode of the launcher to launch a Dragon program. A program is launched by
using the Dragon launch command.</p>
<p>The benefit of fat login mode is that notebooks can be long-running. The
disadvantage is that while computations can be launched on the compute nodes,
the result is not available directly within the notebook. (Should we design a
serializable result to be sent back from a process?). There is no additional
support that is required of the Dragon run-time services required to run in this
mode.</p>
<p>When running Dragon in Server mode, a <em>Specialized Jupyter Kernel</em> is run on the login node
that interacts with the <em>Kernel Back End</em> running on the primary compute node
to provide the notebook kernel functionality on the compute node. The
disadvantage is that notebooks started in this mode only run as long as the
allocation runs. The advantage is that the Jupyter notebook is run within the
context of the Dragon run-time services and has full access to all of the
compute nodes in the allocation. In addition, intermediate results are available
to the notebook.</p>
<p>In Server Mode, the launcher starts two programs and distributes the
responsibilities between these two programs. In the case of Jupyter notebooks
the Specialized Jupyter Kernel provides the interface to the browser because it
is from the login node that socket connections can be made to remote browsers.
The Jupyter Kernel has several socket connections to maintain. The Kernel
Back End provides the REPL environment where Python code is executed and provides
the rest of the services of a Jupyter Python kernel.</p>
<p>The login node <em>Specialized Jupyter Kernel</em> must be written according to the
documentation on making <a class="reference external" href="https://jupyter-client.readthedocs.io/en/stable/kernels.html">kernels in Jupyter</a>. The
<em>Specialized Jupyter Kernel</em> conforms to the requirements of a Jupyter kernel.
The front end functions as a passthru to the <em>Specialized Jupyter Kernel Back
End</em> and passes all incoming messages from the Jupyter front end browser to the
Jupyter back end. The Jupyter messaging requirements are detailed in a document
titled <a class="reference external" href="https://jupyter-client.readthedocs.io/en/stable/messaging.html">Messaging in Jupyter</a>. A Jupyter
kernel has 5 sockets that each serve a different purpose. Messages between the
front end and the back end are defined for requests on these sockets and
responses to the front end (as yet to be determined). The Launcher is not
impacted by the design of the Jupyter support because all messaging between the
Jupyter front end and back end occurs within <a class="reference internal" href="../infrastructure/messages_api.html#lapassthrufb"><span class="std std-ref">LAPassThruFB</span></a> and <a class="reference internal" href="../infrastructure/messages_api.html#lapassthrubf"><span class="std std-ref">LAPassThruBF</span></a>
messages as defined in the <a class="reference internal" href="#launcherservermode"><span class="std std-ref">Launcher Server Mode</span></a> section.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="services.html" class="btn btn-neutral float-left" title="Services" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="global_services.html" class="btn btn-neutral float-right" title="Global Services" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Hewlett Packard Enterprise.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>