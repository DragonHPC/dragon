<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Multi-node process orchestration and node telemetry &mdash; Dragon  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Distributed inference with a Large Language Model (LLM) and node telemetry" href="distr-inf-telemetry.html" />
    <link rel="prev" title="SciPy Image Convolution Benchmark" href="mp_scipy_image.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Dragon
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../start/start.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uguide/uguide.html">Users Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pguide/pguide.html">Programming Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="cbook.html">Solution Cookbook</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="cbook.html#multiprocessing-with-dragon">Multiprocessing with Dragon</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="jupyter.html">Running Jupyter Notebook inside of the Dragon</a></li>
<li class="toctree-l3"><a class="reference internal" href="mp_merge_sort.html">Parallel Merge Sort</a></li>
<li class="toctree-l3"><a class="reference internal" href="mp_queue_demo.html">Parallel Producer - Consumer Communication with Queue</a></li>
<li class="toctree-l3"><a class="reference internal" href="mp_scipy_image.html">SciPy Image Convolution Benchmark</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Multi-node process orchestration and node telemetry</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#usage">Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#optional-arguments">Optional arguments:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#description-of-the-system-used">Description of the system used</a></li>
<li class="toctree-l4"><a class="reference internal" href="#how-to-run">How to run</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="distr-inf-telemetry.html">Distributed inference with a Large Language Model (LLM) and node telemetry</a></li>
<li class="toctree-l3"><a class="reference internal" href="pipeline.html">Creating and Using a Pipeline with Multiprocessing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cbook.html#workflows-with-dragon">Workflows with Dragon</a></li>
<li class="toctree-l2"><a class="reference internal" href="cbook.html#dragon-native">Dragon Native</a></li>
<li class="toctree-l2"><a class="reference internal" href="cbook.html#dragon-data-preview">Dragon Data (Preview)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks/benchmarks.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ref/ref.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infrastructure/infrastructure.html">Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../services/services.html">Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../components/components.html">Low-level Components</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Dragon</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="cbook.html">Solution Cookbook</a></li>
      <li class="breadcrumb-item active">Multi-node process orchestration and node telemetry</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/cbook/torch-scipy-telemetry.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="multi-node-process-orchestration-and-node-telemetry">
<h1>Multi-node process orchestration and node telemetry<a class="headerlink" href="#multi-node-process-orchestration-and-node-telemetry" title="Permalink to this heading"></a></h1>
<p>This is an example of running ensembles of PyTorch and SciPy jobs with the Dragon runtime as well as gathering telemetry data using queues and events.
It demonstrates the life-cycle management of many different processes and node monitoring using Dragon Multiprocessing.</p>
<p>In this example, we gather gpu utilization and the average cpu load over 1 minute. The SciPy job is similar to the one described in the
<a class="reference internal" href="mp_scipy_image.html#scipy-image-convolution-benchmark"><span class="std std-ref">SciPy Image Convolution Benchmark</span></a>. The PyTorch job is similar to the
<a class="reference external" href="https://github.com/pytorch/examples/tree/main/mnist">PyTorch MNIST example</a> and only differs in that each worker trains with a different learning rate.
Currently only Nvidia GPUs are supported since we utilize the py3nvml package to gather the GPU utilization. AMD GPUs can be utilized by gathering similar
info via rocm-smi directly.</p>
<p>The example consists of four components:</p>
<ul class="simple">
<li><p>cpu computation: image processing using the SciPy library</p></li>
<li><p>gpu computation: training on the MNIST dataset</p></li>
<li><p>monitor processes: we start a single process on each node. Every such process gathers telemetry data and pushes the data into a single queue that is shared among the nodes</p></li>
<li><p>a post-processing process: this process gets the data from the queue, processes the data and then prints it. This process can live on any of the nodes, depending on the allocation scheme of Dragon. For now, Dragon follows a round-robin allocation over the available nodes. In the future, Dragon will provide different allocation schemes for the user to choose.</p></li>
</ul>
<p>We start a pool of workers for the mnist computation, a different pool of workers for the SciPy computation, as many monitor processes as the number of nodes
that Dragon uses (it could be a subset of the node allocation) and a single post-processing process. All the workers are distributed across the available nodes.</p>
<p>Figure 1 presents the structure of a toy example with 4 compute nodes and shows the basic architecture and process placement. The shared queue
lives on the same node as the process that created it. In our example, the head/main process creates the queue. The user main program and the head/main process
live on compute node 1.</p>
<figure class="align-default" id="id1">
<a class="reference internal image-reference" href="../_images/telemetry_deployment_diagram.jpg"><img alt="../_images/telemetry_deployment_diagram.jpg" src="../_images/telemetry_deployment_diagram.jpg" style="width: 901.8px; height: 399.0px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text"><strong>Figure 1: Structure of the multi-node process orchestration and node telemetry demo on an allocation of 4 compute nodes</strong></span><a class="headerlink" href="#id1" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>This example consists of the following python files:</p>
<ul class="simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">telemetry_full.py</span></code> - This is the main file. It imports the other files and orchestrates the telemetry work. It contains telem_work, which is the function launched on every node that gathers telemetry data and pushes it to a shared queue, and post_process, which is launched only on one node and reads the telemetry data from the queue and then prints that information.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">telem.py</span></code> - This file has all the functions used to gather telemetry data on each node. It relies heavily on py3nvml to gather this data.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">mnist.py</span></code> - This contains the functions used to run the mnist jobs and utilizes dragon queues to orchestrate GPU placement.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">conv.py</span></code> - This contains all of the functions used for the SciPy convolution jobs.</p></li>
</ul>
<p>Below, we present the main python code (<code class="code docutils literal notranslate"><span class="pre">telemetry_full.py</span></code>) which acts as the coordinator of the whole demo, that combines all the different components.
The code of the other files can be found in the release package, inside <code class="code docutils literal notranslate"><span class="pre">examples/multiprocessing/torch-scipy-telemetry</span></code> directory.</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-number">Listing 7 </span><span class="caption-text"><strong>telemetry_full.py: Multi-node process orchestration and node telemetry with Dragon Multiprocessing</strong></span><a class="headerlink" href="#id2" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">  1</span><span class="kn">import</span> <span class="nn">dragon</span>
<span class="linenos">  2</span><span class="kn">from</span> <span class="nn">dragon.globalservices.node</span> <span class="kn">import</span> <span class="n">get_list</span><span class="p">,</span> <span class="n">query_total_cpus</span>
<span class="linenos">  3</span><span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>
<span class="linenos">  4</span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="linenos">  5</span><span class="kn">import</span> <span class="nn">time</span>
<span class="linenos">  6</span><span class="kn">import</span> <span class="nn">os</span>
<span class="linenos">  7</span><span class="kn">import</span> <span class="nn">queue</span>
<span class="linenos">  8</span>
<span class="linenos">  9</span><span class="kn">import</span> <span class="nn">functools</span>
<span class="linenos"> 10</span><span class="kn">import</span> <span class="nn">mnist</span>
<span class="linenos"> 11</span><span class="kn">import</span> <span class="nn">telem</span> <span class="k">as</span> <span class="nn">tm</span>
<span class="linenos"> 12</span><span class="kn">import</span> <span class="nn">conv</span>
<span class="linenos"> 13</span>
<span class="linenos"> 14</span><span class="k">def</span> <span class="nf">get_args</span><span class="p">():</span>
<span class="linenos"> 15</span>    <span class="sd">&quot;&quot;&quot;Get the user provided arguments</span>
<span class="linenos"> 16</span><span class="sd">    :return args: input args from command line</span>
<span class="linenos"> 17</span><span class="sd">    :rtype args: ArgumentParser object</span>
<span class="linenos"> 18</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 19</span>    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;SciPy and MNIST test with telemetry&quot;</span><span class="p">)</span>
<span class="linenos"> 20</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--scipy_workers&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of scipy workers (default: 2)&quot;</span><span class="p">)</span>
<span class="linenos"> 21</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--mnist_workers&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of mnist workers (default: 2)&quot;</span><span class="p">)</span>
<span class="linenos"> 22</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--bars&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos"> 23</span>                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;uses tqdm bars to print telemetry info&#39;</span><span class="p">)</span>
<span class="linenos"> 24</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--no-cuda&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos"> 25</span>                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;disables CUDA training&#39;</span><span class="p">)</span>
<span class="linenos"> 26</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--size&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;size of the array (default: 1024)&quot;</span><span class="p">)</span>
<span class="linenos"> 27</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 28</span>        <span class="s2">&quot;--mem&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;overall footprint of image dataset to process (default: 1024^3)&quot;</span>
<span class="linenos"> 29</span>    <span class="p">)</span>
<span class="linenos"> 30</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch-size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span>
<span class="linenos"> 31</span>                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;input batch size for training (default: 64)&#39;</span><span class="p">)</span>
<span class="linenos"> 32</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--test-batch-size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span>
<span class="linenos"> 33</span>                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;input batch size for testing (default: 1000)&#39;</span><span class="p">)</span>
<span class="linenos"> 34</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--epochs&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span>
<span class="linenos"> 35</span>                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;number of epochs to train (default: 14)&#39;</span><span class="p">)</span>
<span class="linenos"> 36</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--gamma&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">,</span>
<span class="linenos"> 37</span>                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Learning rate step gamma (default: 0.7)&#39;</span><span class="p">)</span>
<span class="linenos"> 38</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--seed&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;S&#39;</span><span class="p">,</span>
<span class="linenos"> 39</span>                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;random seed (default: 1)&#39;</span><span class="p">)</span>
<span class="linenos"> 40</span>    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
<span class="linenos"> 41</span>
<span class="linenos"> 42</span>    <span class="n">my_args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
<span class="linenos"> 43</span>    <span class="k">return</span> <span class="n">my_args</span>
<span class="linenos"> 44</span>
<span class="linenos"> 45</span><span class="k">def</span> <span class="nf">telem_work</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">start_ev</span><span class="p">,</span> <span class="n">end_ev</span><span class="p">):</span>
<span class="linenos"> 46</span>    <span class="sd">&quot;&quot;&quot;This is used by every monitoring process. It gathers telemetry data</span>
<span class="linenos"> 47</span><span class="sd">    for CPU and GPU utilization and pushed it into the shared queue.</span>
<span class="linenos"> 48</span>
<span class="linenos"> 49</span><span class="sd">    :param q: shared queue that stores the telemetry data for each node</span>
<span class="linenos"> 50</span><span class="sd">    :type q: Dragon Multiprocessing Queue</span>
<span class="linenos"> 51</span><span class="sd">    :param start_ev: event that signals the beginning of monitoring</span>
<span class="linenos"> 52</span><span class="sd">    :type start_ev: Event</span>
<span class="linenos"> 53</span><span class="sd">    :param end_ev: event that signals the end of monitoring</span>
<span class="linenos"> 54</span><span class="sd">    :type end_ev: Event</span>
<span class="linenos"> 55</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 56</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;This is a telemetry process on node </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">uname</span><span class="p">()</span><span class="o">.</span><span class="n">nodename</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos"> 57</span>    <span class="n">start_ev</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span> <span class="c1"># wait until the starting event is set</span>
<span class="linenos"> 58</span>    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="linenos"> 59</span>        <span class="n">gpu_info_list</span> <span class="o">=</span> <span class="n">tm</span><span class="o">.</span><span class="n">call_nvml</span><span class="p">()</span>
<span class="linenos"> 60</span>        <span class="c1"># one process on each node adds to a shared queue</span>
<span class="linenos"> 61</span>        <span class="n">q</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">gpu_info_list</span><span class="p">)</span>
<span class="linenos"> 62</span>        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos"> 63</span>
<span class="linenos"> 64</span>        <span class="c1"># check if the end event is set. If yes, exit.</span>
<span class="linenos"> 65</span>        <span class="k">if</span> <span class="n">end_ev</span><span class="o">.</span><span class="n">is_set</span><span class="p">():</span>
<span class="linenos"> 66</span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Telemetry process on node </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">uname</span><span class="p">()</span><span class="o">.</span><span class="n">nodename</span><span class="si">}</span><span class="s2"> exiting ...&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos"> 67</span>            <span class="k">break</span>
<span class="linenos"> 68</span>
<span class="linenos"> 69</span><span class="k">def</span> <span class="nf">post_process</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">start_ev</span><span class="p">,</span> <span class="n">end_ev</span><span class="p">,</span> <span class="n">tqdm_bars</span><span class="p">):</span>
<span class="linenos"> 70</span>    <span class="sd">&quot;&quot;&quot;This is used by the single post-processing process</span>
<span class="linenos"> 71</span><span class="sd">    that gets the telemetry data from the shared queue and</span>
<span class="linenos"> 72</span><span class="sd">    prints it.</span>
<span class="linenos"> 73</span>
<span class="linenos"> 74</span><span class="sd">    :param q: shared queue that stores the telemetry data for each node</span>
<span class="linenos"> 75</span><span class="sd">    :type q: Dragon Multiprocessing Queue</span>
<span class="linenos"> 76</span><span class="sd">    :param start_ev: event that signals the beginning of monitoring</span>
<span class="linenos"> 77</span><span class="sd">    :type start_ev: Event</span>
<span class="linenos"> 78</span><span class="sd">    :param end_ev: event that signals the end of monitoring</span>
<span class="linenos"> 79</span><span class="sd">    :type end_ev: Event</span>
<span class="linenos"> 80</span><span class="sd">    :param tqdm_bars: flag that signals whether to use bars or not for the presentation of the telemetry data</span>
<span class="linenos"> 81</span><span class="sd">    :type tqdm_bars: Boolean</span>
<span class="linenos"> 82</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 83</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;This is the postprocessing process, </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">uname</span><span class="p">()</span><span class="o">.</span><span class="n">nodename</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos"> 84</span>    <span class="n">start_ev</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span> <span class="c1"># wait until the starting event is set</span>
<span class="linenos"> 85</span>    <span class="n">tqdm_dict</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># used when bars are used for the presentation of the telemetry data</span>
<span class="linenos"> 86</span>    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="linenos"> 87</span>        <span class="c1"># single process reads from the shared queue and prints results</span>
<span class="linenos"> 88</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos"> 89</span>            <span class="n">results_telem</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="linenos"> 90</span>            <span class="k">if</span> <span class="n">tqdm_bars</span><span class="p">:</span>
<span class="linenos"> 91</span>                <span class="n">tm</span><span class="o">.</span><span class="n">updateTelemDict</span><span class="p">(</span><span class="n">results_telem</span><span class="p">,</span> <span class="n">tqdm_dict</span><span class="p">,</span> <span class="n">deviceID</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="linenos"> 92</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 93</span>                <span class="n">tm</span><span class="o">.</span><span class="n">printTelem</span><span class="p">(</span><span class="n">results_telem</span><span class="p">)</span>
<span class="linenos"> 94</span>        <span class="c1"># when the queue is empty, exit</span>
<span class="linenos"> 95</span>        <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">:</span>
<span class="linenos"> 96</span>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Post process is exiting&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos"> 97</span>            <span class="k">break</span>
<span class="linenos"> 98</span>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="linenos"> 99</span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Exception caught: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">100</span>
<span class="linenos">101</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="linenos">102</span>    <span class="n">args</span> <span class="o">=</span> <span class="n">get_args</span><span class="p">()</span>
<span class="linenos">103</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Hello from main process </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">uname</span><span class="p">()</span><span class="o">.</span><span class="n">nodename</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">104</span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;using dragon runtime&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">105</span>    <span class="n">mp</span><span class="o">.</span><span class="n">set_start_method</span><span class="p">(</span><span class="s2">&quot;dragon&quot;</span><span class="p">)</span>
<span class="linenos">106</span>
<span class="linenos">107</span>    <span class="c1"># get the list of nodes from Global Services</span>
<span class="linenos">108</span>    <span class="n">nodeslist</span> <span class="o">=</span> <span class="n">get_list</span><span class="p">()</span>
<span class="linenos">109</span>    <span class="n">nnodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodeslist</span><span class="p">)</span>
<span class="linenos">110</span>
<span class="linenos">111</span>    <span class="n">num_mnist_workers</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">mnist_workers</span>
<span class="linenos">112</span>    <span class="k">assert</span> <span class="n">num_mnist_workers</span> <span class="o">&gt;</span> <span class="mi">1</span>
<span class="linenos">113</span>    <span class="n">num_cpus</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">scipy_workers</span>
<span class="linenos">114</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of nodes: </span><span class="si">{</span><span class="n">nnodes</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">115</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of scipy workers: </span><span class="si">{</span><span class="n">num_cpus</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">116</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of MNIST workers: </span><span class="si">{</span><span class="n">num_mnist_workers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">117</span>
<span class="linenos">118</span>    <span class="c1"># variable used to signal whether to use bars for the presentation of data or not</span>
<span class="linenos">119</span>    <span class="n">use_bars</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">bars</span>
<span class="linenos">120</span>
<span class="linenos">121</span>    <span class="c1"># Initialize the shared queue among the nodes</span>
<span class="linenos">122</span>    <span class="c1"># that is used for the communication of the telemetry data</span>
<span class="linenos">123</span>    <span class="n">q</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
<span class="linenos">124</span>
<span class="linenos">125</span>    <span class="c1"># event used to signal the beginning of monitoring processes</span>
<span class="linenos">126</span>    <span class="n">start_ev</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span>
<span class="linenos">127</span>    <span class="c1"># event used to signal the end of monitoring processes</span>
<span class="linenos">128</span>    <span class="n">end_ev</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span>
<span class="linenos">129</span>
<span class="linenos">130</span>    <span class="c1"># Create a process that gets and processes the telemetry data</span>
<span class="linenos">131</span>    <span class="n">post_proc</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">post_process</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">start_ev</span><span class="p">,</span> <span class="n">end_ev</span><span class="p">,</span> <span class="n">use_bars</span><span class="p">))</span>
<span class="linenos">132</span>    <span class="n">post_proc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="linenos">133</span>
<span class="linenos">134</span>    <span class="c1"># Create a process on each node for monitoring</span>
<span class="linenos">135</span>    <span class="n">procs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos">136</span>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nnodes</span><span class="p">):</span>
<span class="linenos">137</span>        <span class="n">proc</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">telem_work</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">start_ev</span><span class="p">,</span> <span class="n">end_ev</span><span class="p">))</span>
<span class="linenos">138</span>        <span class="n">proc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="linenos">139</span>        <span class="n">procs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proc</span><span class="p">)</span>
<span class="linenos">140</span>
<span class="linenos">141</span>    <span class="c1"># Create a pool of workers for the scipy work</span>
<span class="linenos">142</span>    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos">143</span>    <span class="n">scipy_data</span> <span class="o">=</span> <span class="n">conv</span><span class="o">.</span><span class="n">init_data</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="linenos">144</span>    <span class="n">scipy_pool</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">num_cpus</span><span class="p">)</span>
<span class="linenos">145</span>
<span class="linenos">146</span>    <span class="c1"># Create a pool of workers for the mnist work</span>
<span class="linenos">147</span>    <span class="n">deviceQueue</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">buildDeviceQueue</span><span class="p">()</span>
<span class="linenos">148</span>    <span class="n">lr_list</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">num_mnist_workers</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">i</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_mnist_workers</span><span class="p">)]</span>
<span class="linenos">149</span>    <span class="n">mnist_lr_sweep_partial</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">mnist_lr_sweep</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">deviceQueue</span><span class="p">)</span>
<span class="linenos">150</span>    <span class="n">mnist_pool</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">num_mnist_workers</span><span class="p">)</span>
<span class="linenos">151</span>
<span class="linenos">152</span>    <span class="c1"># start telemetry</span>
<span class="linenos">153</span>    <span class="n">start_ev</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="linenos">154</span>
<span class="linenos">155</span>    <span class="c1"># launch scipy and mnist jobs</span>
<span class="linenos">156</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Launching scipy and mnist jobs&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">157</span>    <span class="n">workers_mnist</span> <span class="o">=</span> <span class="n">mnist_pool</span><span class="o">.</span><span class="n">map_async</span><span class="p">(</span><span class="n">mnist_lr_sweep_partial</span><span class="p">,</span> <span class="n">lr_list</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos">158</span>    <span class="n">workers_scipy</span> <span class="o">=</span> <span class="n">scipy_pool</span><span class="o">.</span><span class="n">map_async</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">f</span><span class="p">,</span> <span class="n">scipy_data</span><span class="p">)</span>
<span class="linenos">159</span>
<span class="linenos">160</span>    <span class="c1"># wait on async processes</span>
<span class="linenos">161</span>    <span class="n">mnist_pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="linenos">162</span>    <span class="n">mnist_pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="linenos">163</span>    <span class="n">scipy_pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="linenos">164</span>    <span class="n">scipy_pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="linenos">165</span>
<span class="linenos">166</span>    <span class="c1"># set the event to signal the end of computation</span>
<span class="linenos">167</span>    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="linenos">168</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shutting down procs&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">169</span>    <span class="n">end_ev</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="linenos">170</span>
<span class="linenos">171</span>    <span class="c1"># wait on the monitoring processes and the post-processing process</span>
<span class="linenos">172</span>    <span class="k">for</span> <span class="n">proc</span> <span class="ow">in</span> <span class="n">procs</span><span class="p">:</span>
<span class="linenos">173</span>        <span class="n">proc</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="linenos">174</span>    <span class="n">post_proc</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="linenos">175</span>    <span class="n">q</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="linenos">176</span>
<span class="linenos">177</span>    <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">workers_mnist</span><span class="o">.</span><span class="n">get</span><span class="p">():</span>
<span class="linenos">178</span>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Final test for learning rate </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">: loss: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> accuracy: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this heading"></a></h2>
<p>It is used as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="go">dragon telemetry_full.py [-h] [--scipy_workers NUM_SCIPY_WORKERS] [--mnist_workers NUM_MNIST_WORKERS] [--bars]</span>
<span class="linenos">2</span><span class="go">                         [--no-cuda] [--size ARRAY_SIZE] [--mem IMAGE_MEM_SIZE] [--batch-size BATCH_SIZE]</span>
<span class="linenos">3</span><span class="go">                         [--test-batch-size TEST_BATCH_SIZE] [--epochs NUM_EPOCHS] [--gamma GAMMA]</span>
<span class="linenos">4</span><span class="go">                         [--seed SEED]</span>
</pre></div>
</div>
</section>
<section id="optional-arguments">
<h2>Optional arguments:<a class="headerlink" href="#optional-arguments" title="Permalink to this heading"></a></h2>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="go">-h, --help            show this help message and exit</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="go">--scipy_workers NUM_SCIPY_WORKERS</span>
<span class="linenos"> 4</span><span class="go">                    number of scipy workers (default: 2)</span>
<span class="linenos"> 5</span><span class="go">--mnist_workers  NUM_MNIST_WORKERS</span>
<span class="linenos"> 6</span><span class="go">                    number of mnist workers (default: 2)</span>
<span class="linenos"> 7</span><span class="go">--bars</span>
<span class="linenos"> 8</span><span class="go">                    uses tqdm bars to print telemetry data</span>
<span class="linenos"> 9</span><span class="go">--no-cuda</span>
<span class="linenos">10</span><span class="go">                    disables CUDA training</span>
<span class="linenos">11</span><span class="go">--size ARRAY_SIZE</span>
<span class="linenos">12</span><span class="go">                    size of the array (default: 1024)</span>
<span class="linenos">13</span><span class="go">--mem IMAGE_MEM_SIZE</span>
<span class="linenos">14</span><span class="go">                    overall footprint of image dataset to process (default: 1024^3)</span>
<span class="linenos">15</span><span class="go">--batch-size BATCH_SIZE</span>
<span class="linenos">16</span><span class="go">                    input batch size for training (default: 64)</span>
<span class="linenos">17</span><span class="go">--test-batch-size TEST_BATCH_SIZE</span>
<span class="linenos">18</span><span class="go">                    input batch size for testing (default: 1000)</span>
<span class="linenos">19</span><span class="go">--epochs NUM_EPOCHS</span>
<span class="linenos">20</span><span class="go">                    number of epochs to train (default: 14)</span>
<span class="linenos">21</span><span class="go">--gamma</span>
<span class="linenos">22</span><span class="go">                    Learning rate step gamma (default: 0.7)</span>
<span class="linenos">23</span><span class="go">--seed</span>
<span class="linenos">24</span><span class="go">                    random seed (default: 1)</span>
</pre></div>
</div>
</section>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h2>
<p>After installing dragon, the remaining packages needed to install are located in the requirements.txt file.
The version of PyTorch and it’s dependencies may need to be made to run on other systems.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="go">&gt; pip install -r requirements.txt</span>
</pre></div>
</div>
<p>Alternatively, the packages and their dependencies can be installed individually. The PyTorch version and corresponding pip command
can be found <a class="reference external" href="https://pytorch.org/get-started/locally/">here</a>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="go">&gt; pip3 install torch torchvision torchaudio</span>
<span class="linenos">2</span><span class="go">&gt; pip install py3nvml</span>
<span class="linenos">3</span><span class="go">&gt; pip install tqdm</span>
<span class="linenos">4</span><span class="go">&gt; pip install scipy</span>
</pre></div>
</div>
</section>
<section id="description-of-the-system-used">
<h2>Description of the system used<a class="headerlink" href="#description-of-the-system-used" title="Permalink to this heading"></a></h2>
<p>For this example, an HPE Cray EX was used. Each node has AMD EPYC 7763 64-core
CPUs and 4x Nvidia A100 GPUs.</p>
</section>
<section id="how-to-run">
<h2>How to run<a class="headerlink" href="#how-to-run" title="Permalink to this heading"></a></h2>
<section id="example-output-when-run-on-2-nodes-with-2-mnist-workers-and-2-scipy-workers-on-pinoak">
<h3>Example Output when run on 2 nodes with 2 MNIST workers and 2 SciPy workers on Pinoak<a class="headerlink" href="#example-output-when-run-on-2-nodes-with-2-mnist-workers-and-2-scipy-workers-on-pinoak" title="Permalink to this heading"></a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="go">&gt; salloc --exclusive -N 2 -p allgriz</span>
<span class="linenos"> 2</span><span class="go">&gt; dragon telemetry_full.py</span>
<span class="linenos"> 3</span><span class="go">Hello from main process pinoak0033.</span>
<span class="linenos"> 4</span><span class="go">using dragon runtime</span>
<span class="linenos"> 5</span><span class="go">Number of nodes: 2</span>
<span class="linenos"> 6</span><span class="go">Number of scipy workers: 2</span>
<span class="linenos"> 7</span><span class="go">Number of MNIST workers: 2</span>
<span class="linenos"> 8</span><span class="go">This is a telemetry process on node pinoak0033.</span>
<span class="linenos"> 9</span><span class="go">Number of images: 1024</span>
<span class="linenos">10</span><span class="go">This is a telemetry process on node pinoak0034.</span>
<span class="linenos">11</span><span class="go">This is the postprocessing process, pinoak0034.</span>
<span class="linenos">12</span><span class="go">Launching scipy and mnist jobs</span>
<span class="linenos">13</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.17 device # 0 utilization: 0.00%</span>
<span class="linenos">14</span><span class="go">nodename: pinoak0034 cpu load average 1 minute: 0.34 device # 0 utilization: 0.00%</span>
<span class="linenos">15</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.17 device # 0 utilization: 0.00%</span>
<span class="linenos">16</span><span class="go">nodename: pinoak0034 cpu load average 1 minute: 0.34 device # 0 utilization: 0.00%</span>
<span class="linenos">17</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.17 device # 0 utilization: 0.00%</span>
<span class="linenos">18</span><span class="go">nodename: pinoak0034 cpu load average 1 minute: 0.72 device # 0 utilization: 0.00%</span>
<span class="linenos">19</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.31 device # 0 utilization: 0.00%</span>
<span class="linenos">20</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.31 device # 0 utilization: 0.00%</span>
<span class="linenos">21</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.31 device # 0 utilization: 1.00%</span>
<span class="linenos">22</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.31 device # 0 utilization: 0.00%</span>
<span class="linenos">23</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.31 device # 0 utilization: 1.00%</span>
<span class="linenos">24</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.69 device # 0 utilization: 0.00%</span>
<span class="linenos">25</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.69 device # 0 utilization: 2.00%</span>
<span class="linenos">26</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.69 device # 0 utilization: 10.00%</span>
<span class="linenos">27</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.69 device # 0 utilization: 10.00%</span>
<span class="linenos">28</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.96 device # 0 utilization: 10.00%</span>
<span class="linenos">29</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.96 device # 0 utilization: 10.00%</span>
<span class="linenos">30</span><span class="go">nodename: pinoak0034 cpu load average 1 minute: 0.91 device # 0 utilization: 0.00%</span>
<span class="linenos">31</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 0.96 device # 0 utilization: 10.00%</span>
<span class="linenos">32</span><span class="go">nodename: pinoak0034 cpu load average 1 minute: 0.91 device # 0 utilization: 2.00%</span>
<span class="linenos">33</span><span class="go">.</span>
<span class="linenos">34</span><span class="go">.</span>
<span class="linenos">35</span><span class="go">.</span>
<span class="linenos">36</span><span class="go">&lt; More Telemetry Data &gt;</span>
<span class="linenos">37</span><span class="go">.</span>
<span class="linenos">38</span><span class="go">.</span>
<span class="linenos">39</span><span class="go">.</span>
<span class="linenos">40</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 33.97 device # 0 utilization: 2.00%</span>
<span class="linenos">41</span><span class="go">nodename: pinoak0034 cpu load average 1 minute: 29.7 device # 0 utilization: 3.00%</span>
<span class="linenos">42</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 33.97 device # 0 utilization: 0.00%</span>
<span class="linenos">43</span><span class="go">nodename: pinoak0034 cpu load average 1 minute: 29.7 device # 0 utilization: 0.00%</span>
<span class="linenos">44</span><span class="go">nodename: pinoak0033 cpu load average 1 minute: 33.97 device # 0 utilization: 0.00%</span>
<span class="linenos">45</span><span class="go">nodename: pinoak0034 cpu load average 1 minute: 27.4 device # 0 utilization: 0.00%</span>
<span class="linenos">46</span><span class="go">.</span>
<span class="linenos">47</span><span class="go">.</span>
<span class="linenos">48</span><span class="go">.</span>
<span class="linenos">49</span><span class="go">&lt; More Telemetry Data &gt;</span>
<span class="linenos">50</span><span class="go">.</span>
<span class="linenos">51</span><span class="go">.</span>
<span class="linenos">52</span><span class="go">.</span>
<span class="linenos">53</span><span class="go">Shutting down procs</span>
<span class="linenos">54</span><span class="go">Telemetry process on node pinoak0033 exiting ...</span>
<span class="linenos">55</span><span class="go">Telemetry process on node pinoak0034 exiting ...</span>
<span class="linenos">56</span><span class="go">Post process is exiting</span>
<span class="linenos">57</span><span class="go">Final test for learning rate 0.5: loss: 0.02791020164489746 accuracy: 99.1</span>
<span class="linenos">58</span><span class="go">Final test for learning rate 1.5: loss: 0.027457854652404787 accuracy: 99.21</span>
</pre></div>
</div>
<p>Running with –bars will print the information using tqdm bars that are updated. The utilization for all GPUs on each node will be printed
along with the cpu load average. Mid-run the output should look like:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="go">&gt; dragon telemetry_full.py --bars</span>
<span class="linenos"> 2</span><span class="go">Hello from main process pinoak0033.</span>
<span class="linenos"> 3</span><span class="go">using dragon runtime</span>
<span class="linenos"> 4</span><span class="go">Number of nodes: 2</span>
<span class="linenos"> 5</span><span class="go">Number of scipy workers: 2</span>
<span class="linenos"> 6</span><span class="go">Number of MNIST workers: 2</span>
<span class="linenos"> 7</span><span class="go">This is the postprocessing process, pinoak0034.</span>
<span class="linenos"> 8</span><span class="go">This is a telemetry process on node pinoak0033.</span>
<span class="linenos"> 9</span><span class="go">This is a telemetry process on node pinoak0034.</span>
<span class="linenos">10</span><span class="go">Number of images: 1024</span>
<span class="linenos">11</span><span class="go">Launching scipy and mnist jobs</span>
<span class="linenos">12</span><span class="go">pinoak0034 cpu load avg.:  22%|██▏       | 22.07/100 [00:55&lt;03:14,  2.50s/it]</span>
<span class="linenos">13</span><span class="go">pinoak0034 device 0 util:   9%|▉         | 9/100 [00:55&lt;09:17,  6.13s/it]</span>
<span class="linenos">14</span><span class="go">pinoak0034 device 1 util:   0%|          | 0/100 [00:55&lt;?, ?it/s]</span>
<span class="linenos">15</span><span class="go">pinoak0034 device 2 util:   0%|          | 0/100 [00:55&lt;?, ?it/s]</span>
<span class="linenos">16</span><span class="go">pinoak0034 device 3 util:   0%|          | 0/100 [00:55&lt;?, ?it/s]</span>
<span class="linenos">17</span><span class="go">pinoak0033 cpu load avg.:  15%|█▌        | 15.03/100 [00:54&lt;05:09,  3.64s/it]</span>
<span class="linenos">18</span><span class="go">pinoak0033 device 0 util:   9%|▉         | 9/100 [00:54&lt;09:13,  6.08s/it]</span>
<span class="linenos">19</span><span class="go">pinoak0033 device 1 util:   0%|          | 0/100 [00:54&lt;?, ?it/s]</span>
<span class="linenos">20</span><span class="go">pinoak0033 device 2 util:   0%|          | 0/100 [00:54&lt;?, ?it/s]</span>
<span class="linenos">21</span><span class="go">pinoak0033 device 3 util:   0%|          | 0/100 [00:54&lt;?, ?it/s]</span>
</pre></div>
</div>
</section>
<section id="example-output-when-run-on-4-nodes-with-8-mnist-workers-and-16-scipy-workers-on-pinoak">
<h3>Example Output when run on 4 nodes with 8 MNIST workers and 16 SciPy workers on Pinoak<a class="headerlink" href="#example-output-when-run-on-4-nodes-with-8-mnist-workers-and-16-scipy-workers-on-pinoak" title="Permalink to this heading"></a></h3>
<p>We can run with more nodes and utilize more GPUs per node by increasing the number of MNIST workers. For example, in the following we see that devices 0 and 1 are used on all 4 nodes.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="go">&gt; dragon telemetry_full.py --scipy_workers 16 --mnist_workers 8 --epochs 3 --bars</span>
<span class="linenos"> 2</span><span class="go">Hello from main process pinoak0033.</span>
<span class="linenos"> 3</span><span class="go">using dragon runtime</span>
<span class="linenos"> 4</span><span class="go">Number of nodes: 4</span>
<span class="linenos"> 5</span><span class="go">Number of scipy workers: 16</span>
<span class="linenos"> 6</span><span class="go">Number of MNIST workers: 8</span>
<span class="linenos"> 7</span><span class="go">This is a telemetry process on node pinoak0035.</span>
<span class="linenos"> 8</span><span class="go">This is a telemetry process on node pinoak0036.</span>
<span class="linenos"> 9</span><span class="go">This is a telemetry process on node pinoak0034.</span>
<span class="linenos">10</span><span class="go">This is the postprocessing process, pinoak0034.</span>
<span class="linenos">11</span><span class="go">This is a telemetry process on node pinoak0033.</span>
<span class="linenos">12</span><span class="go">Number of images: 1024</span>
<span class="linenos">13</span><span class="go">Launching scipy and mnist jobs</span>
<span class="linenos">14</span><span class="go">pinoak0033 cpu load avg.:  22%|██▏       | 21.73/100 [00:32&lt;01:57,  1.51s/it]</span>
<span class="linenos">15</span><span class="go">pinoak0033 device 0 util:   8%|▊         | 8/100 [00:32&lt;06:16,  4.09s/it]</span>
<span class="linenos">16</span><span class="go">pinoak0033 device 1 util:   8%|▊         | 8/100 [00:32&lt;06:16,  4.09s/it]</span>
<span class="linenos">17</span><span class="go">pinoak0033 device 2 util:   0%|          | 0/100 [00:32&lt;?, ?it/s]</span>
<span class="linenos">18</span><span class="go">pinoak0033 device 3 util:   0%|          | 0/100 [00:32&lt;?, ?it/s]</span>
<span class="linenos">19</span><span class="go">pinoak0034 cpu load avg.:  11%|█▏        | 11.42/100 [00:32&lt;04:10,  2.83s/it]</span>
<span class="linenos">20</span><span class="go">pinoak0034 device 0 util:   8%|▊         | 8/100 [00:32&lt;06:11,  4.04s/it]</span>
<span class="linenos">21</span><span class="go">pinoak0034 device 1 util:   9%|▉         | 9/100 [00:32&lt;05:26,  3.59s/it]</span>
<span class="linenos">22</span><span class="go">pinoak0034 device 2 util:   0%|          | 0/100 [00:32&lt;?, ?it/s]</span>
<span class="linenos">23</span><span class="go">pinoak0034 device 3 util:   0%|          | 0/100 [00:32&lt;?, ?it/s]</span>
<span class="linenos">24</span><span class="go">pinoak0035 cpu load avg.:  16%|█▋        | 16.46/100 [00:32&lt;02:45,  1.98s/it]</span>
<span class="linenos">25</span><span class="go">pinoak0035 device 0 util:   9%|▉         | 9/100 [00:32&lt;05:29,  3.62s/it]</span>
<span class="linenos">26</span><span class="go">pinoak0035 device 1 util:   8%|▊         | 8/100 [00:32&lt;06:14,  4.07s/it]</span>
<span class="linenos">27</span><span class="go">pinoak0035 device 2 util:   0%|          | 0/100 [00:32&lt;?, ?it/s]</span>
<span class="linenos">28</span><span class="go">pinoak0035 device 3 util:   0%|          | 0/100 [00:32&lt;?, ?it/s]</span>
<span class="linenos">29</span><span class="go">pinoak0036 cpu load avg.:   7%|▋         | 6.56/100 [00:32&lt;07:44,  4.97s/it]</span>
<span class="linenos">30</span><span class="go">pinoak0036 device 0 util:   8%|▊         | 8/100 [00:32&lt;06:14,  4.07s/it]</span>
<span class="linenos">31</span><span class="go">pinoak0036 device 1 util:   9%|▉         | 9/100 [00:32&lt;05:29,  3.62s/it]</span>
<span class="linenos">32</span><span class="go">pinoak0036 device 2 util:   0%|          | 0/100 [00:32&lt;?, ?it/s]</span>
<span class="linenos">33</span><span class="go"> ... (more hidden) ...</span>
</pre></div>
</div>
<p>The same shut down message as above will be printed when the job is finished. Note, the first time this is run, the MNIST data set will
be downloaded and will lead to additional output.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mp_scipy_image.html" class="btn btn-neutral float-left" title="SciPy Image Convolution Benchmark" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="distr-inf-telemetry.html" class="btn btn-neutral float-right" title="Distributed inference with a Large Language Model (LLM) and node telemetry" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Hewlett Packard Enterprise.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>